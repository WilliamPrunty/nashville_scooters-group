{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7971b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "#importing sqlalchemy to utilize SQL queries in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'scooter'    \n",
    "\n",
    "connection_string = f\"postgresql://postgres:postgres@localhost:5432/{database_name}\"\n",
    "\n",
    "#connecting scooter database\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "#creating the engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a database for the trips table.\n",
    "\n",
    "allcompanies = '''\n",
    "SELECT *\n",
    "FROM trips\n",
    "'''\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    allcompanies_df = pd.read_sql(text(allcompanies), con = connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding min and max dates in the database, should only include 3 months (May, June, July)\n",
    "\n",
    "date_range= '''\n",
    "SELECT MIN(pubdatetime), MAX(pubdatetime)\n",
    "FROM scooters\n",
    "'''\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    date_range_df = pd.read_sql(text(date_range), con = connection)\n",
    "    \n",
    "date_range_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving as new dataframe\n",
    "\n",
    "allcompanies_df.to_csv('../data/allcompanies_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae628b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling back the new dataframe to more easily assign new datatypes as needed.\n",
    "\n",
    "trips = pd.read_csv('../data/allcompanies_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d95aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the new dataframe, resetting index and dropping old indexed columns. \n",
    "\n",
    "trips = trips.reset_index(drop=True)\n",
    "trips = trips.drop(columns='Unnamed: 0')\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ee7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating datetime object of trip starttime and startdate, verifying with .info() that type has changed.\n",
    "\n",
    "trips['startdatetime'] = trips['startdate'] + \" \" + trips['starttime']\n",
    "trips['startdatetime'] = pd.to_datetime(trips['startdatetime'])\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating datetime object of trip endtime and enddate, verifying with .info that type has changed.\n",
    "\n",
    "trips['enddatetime'] = trips['enddate'] + \" \" + trips['endtime']\n",
    "trips['enddatetime'] = pd.to_datetime(trips['enddatetime'])\n",
    "trips.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6359c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifying cleaning steps and object creation.\n",
    "\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating new trip duration based on data given, during previous investigation found that trip duration\n",
    "#for Bolt Mobility and JUMP was misrepresented. Bolt is assumed to be displayed in seconds, \n",
    "#JUMP seems to max at 1440 minutes regardless of start and end times.\n",
    "\n",
    "trips['tripduration'] = trips['enddatetime'] - trips['startdatetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating timedeltas for future comparison\n",
    "\n",
    "oneminute = dt.timedelta(minutes=1)\n",
    "oneday = dt.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24586333",
   "metadata": {},
   "source": [
    "### 2. According to Second Substitute Bill BL2018-1202, all permitted operators will first clean data before providing or reporting data to Metro. Data processing and cleaning shall include:  \n",
    "     Removal of staff servicing and test trips  \n",
    "     Removal of trips below one minute  \n",
    "     Trip lengths are capped at 24 hours\n",
    "Are the scooter companies in compliance with the second and third part of this rule? \n",
    "\n",
    "##### focusing on question 2 first, as the end result will be the data I use to answer the remaining questions. This question serves as a cleaning step, utilizing some groundwork laid above and with the guidelines here, I will filter to only relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eca5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating columns to further calculate how many rows and \n",
    "#within which direction companies are not compliant.\n",
    "#additionally beginning to remove trips with a NEGATIVE distance or any trips greater than 20miles\n",
    "#or 105600 feet, the average scooter range. \n",
    "\n",
    "trips['under1minute'] = trips['tripduration'] < oneminute\n",
    "trips['over1day'] = trips['tripduration'] > oneday\n",
    "trips['negativedistance'] = trips['tripdistance'] < 0\n",
    "trips['over20miles'] = trips['tripdistance'] > 105600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displays the percentage of rows in compliance with the 'removal of trips below one minute'\n",
    "#guideline, where 'False' represents rows that ARE IN compliance.\n",
    "\n",
    "trips.groupby(by='companyname').under1minute.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f28a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displays the percentage of rows in compliance with the 'trip lengths are capped at 24 hours'\n",
    "#guideline, where 'False' represents rows that ARE IN compliance.\n",
    "\n",
    "trips.groupby(by='companyname').over1day.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84ed59",
   "metadata": {},
   "source": [
    "## Q2 Answer\n",
    "Gotcha, JUMP, and SPIN are in compliance with no trips under 1 minute in length, all other companies are not. \n",
    "\n",
    "Bird, Gotcha, and Lime are in compliance with no trips over 24 hours in length, all other companies are not.\n",
    "\n",
    "No company was in compliance of both rules. Data for Bolt Mobility and JUMP were both misrepresented in the data based on the given data dictionary. Bolt Mobility reported trip durations in seconds. JUMP simply capped the 'tripduration' column at 1440 minutes (24 hours) regardless of the proper calculation between start and end times. \n",
    "These were corrected above and before this question was officially answered. 'tripduration' is now a calculated column between 'startdatetime' and 'enddatetime', these are datetime objects created by concatenating relevant information and assigning a new datatype to the created column.\n",
    "\n",
    "Moving forward, I will remove the offending rows and continue analysis with only rows that are in compliance. \n",
    "\n",
    "Initially there are 565522 rows. There are 12535 rows not in compliance. There are 34747 duplicate rows, largely from Lime. Discovered 106 rows with negative tripdistances or tripdistances that were well in excess of 20 miles, removed negatives and filtered data to only trips under 20 miles or the average range of a fully charged SUMD. Filtered and removed from dataset as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, checking for any duplicated rows within the data. Exporting duplicates to .csv.\n",
    "\n",
    "tripsduplicated = trips.loc[trips.duplicated(subset=['sumdid', 'starttime', 'startdate'], keep='first') == True]\n",
    "tripsduplicated.to_csv('../data/tripsduplicated.csv')\n",
    "tripsduplicated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting duplicates by company\n",
    "\n",
    "trips.loc[trips.duplicated(subset=['sumdid', 'starttime', 'startdate'], keep='first') == True].value_counts('companyname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeac12f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#removing duplicated rows as first part of cleaning.\n",
    "\n",
    "tripscleaned = trips.drop_duplicates(subset=['sumdid', 'starttime', 'startdate'], keep='first', inplace=False, ignore_index=False)\n",
    "tripscleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe of the trips that are not in compliance, maybe useful for future analysis.\n",
    "#there are 12535 rows not in compliance. \n",
    "\n",
    "tripnegativedistance = trips[(trips['negativedistance'] == True)]\n",
    "tripover20miles = trips[(trips['over20miles'] == True)]\n",
    "distanceerrors = pd.concat([tripnegativedistance, tripover20miles], ignore_index=True, axis=0)\n",
    "notincomplianceminute = trips[(trips['under1minute'] == True)]\n",
    "notincomplianceday = trips[(trips['over1day'] == True)]\n",
    "notincompliance = pd.concat([notincomplianceminute, notincomplianceday], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalizing the cleaning steps, dropping the filtering columns. Verifying the new shape matches expectactions.\n",
    "tripscleaned = tripscleaned[(tripscleaned['negativedistance'] == False) & (tripscleaned['over20miles'] == False)]\n",
    "tripscleaned = tripscleaned[(tripscleaned['under1minute'] == False) & (tripscleaned['over1day'] == False)]\n",
    "tripscleaned = tripscleaned.reset_index(drop=True)\n",
    "tripscleaned = tripscleaned.drop(columns=['under1minute', 'over1day', 'over20miles', 'negativedistance'])\n",
    "tripscleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new .csv files of the cleaned data to continue analysis in another notebook. \n",
    "\n",
    "#distanceerrors.to_csv('../data/distanceerrors.csv')\n",
    "#notincompliance.to_csv('../data/notincompliance.csv')\n",
    "#tripscleaned.to_csv('../data/tripscleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade2bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
